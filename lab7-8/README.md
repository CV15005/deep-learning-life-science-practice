
# Лабораторная работа №7
## Отслеживание ML-экспериментов

[Простой пример с MLflow](https://www.kaggle.com/code/kvsbmstu/pytorch-mlflow-cifar10)

[Простой пример с Weights & Biases - wandb](https://www.kaggle.com/code/kvsbmstu/pytorch-wandb-cifar10)

[Простой пример с ClearML](https://www.kaggle.com/code/kvsbmstu/pytorch-clearml-cifar10)

#### Задание
В рамках лабораторной работы необходимо обучить собственную нейросетевую модель (необязательно классификации изображений, как в примере) на интересном вам датасете.
При этом опробуйте каждое из решений для трекинга ML-экспериментов. Добавьте сохранение на сервере весов модели.



# Лабораторная работа №8
## Оптимизация гиперпараметров моделей

[Простой пример с Optuna](https://www.kaggle.com/code/kvsbmstu/test-optuna)

[Пример поиска гиперпараметров с помощью wandb sweeps](https://www.kaggle.com/code/kvsbmstu/wandb-sweep-pytorch)

Схожий функционал поиска гиперпараметров есть и в ClearML.

[Много полезных материалов по ClearML на русском языке, связка Lightning + ClearML, есть примеры по оптимизации гиперпараметров](https://github.com/a-milenkin/ml_instruments/tree/f9cfe56b418f06565e6a777a8b12e9aa99cef1c4/notebooks)

[Ссылка на актуальный пример оптимизации гиперпараметров из документации ClearML, используется keras](https://github.com/clearml/clearml/tree/master/examples/optimization/hyper-parameter-optimization)

#### Задание
Примените wandb sweeps для поиска оптимальных параметров вашей модели из лабораторной работы №7.

